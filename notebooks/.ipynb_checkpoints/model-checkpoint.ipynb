{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import h5py as h5\n",
    "import keras.backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 12602\n",
    "MAX_QUESTION_LEN = 26"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 22,
>>>>>>> 7e28458e9f3e47030b8d168f4cd8eb5baab69e42
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQANet:\n",
    "    def __init__(self, combine_type, question_embed_dim, lstm_dim, n_answers):\n",
    "        self.combine_type = combine_type\n",
    "        self.question_embed_dim = question_embed_dim\n",
    "        self.lstm_dim = lstm_dim\n",
    "        self.n_answers = n_answers\n",
    "        self.build()\n",
    "        \n",
    "    def build(self):\n",
    "        \n",
    "        image_features = tf.keras.layers.Input(shape=(4096,), \n",
    "                                                   dtype='float32')\n",
    "            \n",
    "        image_embedding = tf.keras.layers.Dense(units=self.question_embed_dim, \n",
    "                                                activation='elu',\n",
    "                                                name='image_embedding')(inputs=image_features)\n",
    "        \n",
    "        if self.combine_type == 'show_and_tell':\n",
    "            concat_axis = 1\n",
    "            image_embedding = tf.keras.layers.Reshape((1, self.question_embed_dim))(image_embedding)\n",
    "        elif self.combine_type == 'feed_CNN_to_all':\n",
    "            concat_axis = -1\n",
    "            image_embedding = tf.keras.layers.RepeatVector(MAX_QUESTION_LEN)(image_embedding)\n",
    "            \n",
<<<<<<< HEAD
    "            question_input = tf.keras.layers.Input(shape=(MAX_QUESTION_LEN,), \n",
    "                                                   dtype='int32',\n",
    "                                                   name='question_input')\n",
    "            \n",
    "            question_input_masked = tf.keras.layers.Masking(mask_value=0, \n",
    "                                                           input_shape=(MAX_QUESTION_LEN,))(inputs=question_input)\n",
    "            \n",
    "            question_embedding = tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, \n",
    "                                                           output_dim=self.question_embed_dim, \n",
    "                                                           input_length=MAX_QUESTION_LEN,\n",
    "                                                           name='question_embedding')(inputs=question_input_masked)\n",
    "             \n",
    "            image_question_embedding = tf.keras.layers.Concatenate(axis=1, \n",
    "                                                                   name='image_question_embedding')(inputs=[image_embedding, question_embedding])\n",
    "            \n",
    "            question_features, last_h, _ = tf.keras.layers.LSTM(units=self.lstm_dim, \n",
    "                                                                return_sequences=True, \n",
    "                                                                return_state=True, \n",
    "                                                                name='question_generator')(inputs=image_question_embedding)\n",
=======
    "        question_input = tf.keras.layers.Input(shape=(MAX_QUESTION_LEN,), \n",
    "                                               dtype='int32',\n",
    "                                               name='question_input')\n",
>>>>>>> 7e28458e9f3e47030b8d168f4cd8eb5baab69e42
    "\n",
    "        question_embedding = tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, \n",
    "                                                       output_dim=self.question_embed_dim, \n",
    "                                                       input_length=MAX_QUESTION_LEN,\n",
    "                                                       name='question_embedding')(inputs=question_input)\n",
    "\n",
    "        image_question_embedding = tf.keras.layers.Concatenate(axis=concat_axis, \n",
    "                                                               name='image_question_embedding')(inputs=[image_embedding, question_embedding])\n",
    "\n",
    "        question_features, last_h, _ = tf.keras.layers.LSTM(units=self.lstm_dim, \n",
    "                                                            return_sequences=True, \n",
    "                                                            return_state=True, \n",
    "                                                            name='question_generator')(inputs=image_question_embedding)\n",
    "\n",
    "        question_pred = tf.keras.layers.TimeDistributed(layer=tf.keras.layers.Dense(units=VOCAB_SIZE, \n",
    "                                                                                    activation='softmax', \n",
    "                                                                                    name='word_classifier'))(inputs=question_features)\n",
    "\n",
    "        if self.combine_type == 'show_and_tell':\n",
    "            question_pred = tf.keras.layers.Lambda(lambda x: x[:, :-1, :], \n",
    "                                                   name='ignore_last_word')(inputs=question_pred)\n",
    "\n",
    "        answer_fc1 = tf.keras.layers.Dense(units=1000,\n",
    "                                            activation='elu',\n",
    "                                            name='answer_dense_1')(inputs=last_h)\n",
    "\n",
    "        answer_fc2 = tf.keras.layers.Dense(units=1000,\n",
    "                                            activation='elu',\n",
    "                                            name='answer_dense_2')(inputs=answer_fc1)\n",
    "\n",
    "        answer_pred = tf.keras.layers.Dense(units=self.n_answers,\n",
    "                                            activation='softmax',\n",
    "                                            name='answer_classifier')(inputs=answer_fc2)\n",
    "\n",
    "        self.model = tf.keras.Model(inputs=[image_features, question_input], \n",
    "                                    outputs=[question_pred, answer_pred])  \n",
    "\n",
    "        self.model.compile(loss='categorical_crossentropy', \n",
    "                           optimizer='adam', metrics=['accuracy'])\n",
    "            \n",
    "    \n",
    "    def train(self, x_train, y_train, x_val, y_val, batch_size, epochs):\n",
    "        self.model.fit(x=x_train, \n",
    "                       y=y_train, \n",
    "                       batch_size=batch_size, \n",
    "                       epochs=epochs, \n",
    "                       verbose=1,\n",
    "                       validation_split=0.2,\n",
    "                       shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 23,
>>>>>>> 7e28458e9f3e47030b8d168f4cd8eb5baab69e42
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "question_embed_dim = 256\n",
    "lstm_dim = 512\n",
    "n_answers = 1000\n",
    "n_train = 1000"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 25,
>>>>>>> 7e28458e9f3e47030b8d168f4cd8eb5baab69e42
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4096)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
<<<<<<< HEAD
      "input_5 (InputLayer)            (None, 4096)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question_input (InputLayer)     (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_embedding (Dense)         (None, 256)          1048832     input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking_4 (Masking)             (None, 26)           0           question_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 256)       0           image_embedding[0][0]            \n",
=======
      "input_8 (InputLayer)            (None, 4096)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_embedding (Dense)         (None, 256)          1048832     input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "question_input (InputLayer)     (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 26, 256)      0           image_embedding[0][0]            \n",
>>>>>>> 7e28458e9f3e47030b8d168f4cd8eb5baab69e42
      "__________________________________________________________________________________________________\n",
      "question_embedding (Embedding)  (None, 26, 256)      3226112     masking_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
<<<<<<< HEAD
      "image_question_embedding (Conca (None, 27, 256)      0           reshape_4[0][0]                  \n",
=======
      "image_question_embedding (Conca (None, 26, 512)      0           repeat_vector[0][0]              \n",
>>>>>>> 7e28458e9f3e47030b8d168f4cd8eb5baab69e42
      "                                                                 question_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "question_generator (LSTM)       [(None, 26, 512), (N 2099200     image_question_embedding[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "answer_dense_1 (Dense)          (None, 1000)         513000      question_generator[0][1]         \n",
      "__________________________________________________________________________________________________\n",
<<<<<<< HEAD
      "time_distributed (TimeDistribut (None, 27, 12602)    6464826     question_generator[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "answer_dense_2 (Dense)          (None, 1000)         1001000     answer_dense_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "ignore_last_word (Lambda)       (None, 26, 12602)    0           time_distributed[0][0]           \n",
=======
      "time_distributed_4 (TimeDistrib (None, 26, 12602)    6464826     question_generator[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "answer_dense_2 (Dense)          (None, 1000)         1001000     answer_dense_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "ignore_last_word (Lambda)       (None, 25, 12602)    0           time_distributed_4[0][0]         \n",
>>>>>>> 7e28458e9f3e47030b8d168f4cd8eb5baab69e42
      "__________________________________________________________________________________________________\n",
      "answer_classifier (Dense)       (None, 1000)         1001000     answer_dense_2[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 15,353,970\n",
      "Trainable params: 15,353,970\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
<<<<<<< HEAD
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddharth/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 42s 53ms/step - loss: 12.3703 - ignore_last_word_loss: 6.5880 - answer_classifier_loss: 5.7822 - ignore_last_word_acc: 0.7152 - answer_classifier_acc: 0.1800 - val_loss: 6.8602 - val_ignore_last_word_loss: 1.7209 - val_answer_classifier_loss: 5.1393 - val_ignore_last_word_acc: 0.7463 - val_answer_classifier_acc: 0.0050\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 6.0456 - ignore_last_word_loss: 1.6109 - answer_classifier_loss: 4.4346 - ignore_last_word_acc: 0.7425 - answer_classifier_acc: 0.2062 - val_loss: 6.0950 - val_ignore_last_word_loss: 1.5273 - val_answer_classifier_loss: 4.5678 - val_ignore_last_word_acc: 0.7519 - val_answer_classifier_acc: 0.2550\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 5.6749 - ignore_last_word_loss: 1.3688 - answer_classifier_loss: 4.3060 - ignore_last_word_acc: 0.7516 - answer_classifier_acc: 0.2375 - val_loss: 6.3120 - val_ignore_last_word_loss: 1.4447 - val_answer_classifier_loss: 4.8673 - val_ignore_last_word_acc: 0.7623 - val_answer_classifier_acc: 0.2550\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 5.4411 - ignore_last_word_loss: 1.3067 - answer_classifier_loss: 4.1345 - ignore_last_word_acc: 0.7593 - answer_classifier_acc: 0.2088 - val_loss: 6.2484 - val_ignore_last_word_loss: 1.4101 - val_answer_classifier_loss: 4.8382 - val_ignore_last_word_acc: 0.7715 - val_answer_classifier_acc: 0.2550\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 5.4073 - ignore_last_word_loss: 1.2657 - answer_classifier_loss: 4.1416 - ignore_last_word_acc: 0.7645 - answer_classifier_acc: 0.2300 - val_loss: 6.1184 - val_ignore_last_word_loss: 1.3876 - val_answer_classifier_loss: 4.7309 - val_ignore_last_word_acc: 0.7752 - val_answer_classifier_acc: 0.2000\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 5.3548 - ignore_last_word_loss: 1.2169 - answer_classifier_loss: 4.1379 - ignore_last_word_acc: 0.7760 - answer_classifier_acc: 0.2350 - val_loss: 6.4527 - val_ignore_last_word_loss: 1.3509 - val_answer_classifier_loss: 5.1017 - val_ignore_last_word_acc: 0.7856 - val_answer_classifier_acc: 0.2550\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 5.3509 - ignore_last_word_loss: 1.1725 - answer_classifier_loss: 4.1784 - ignore_last_word_acc: 0.7864 - answer_classifier_acc: 0.2287 - val_loss: 6.1076 - val_ignore_last_word_loss: 1.3274 - val_answer_classifier_loss: 4.7803 - val_ignore_last_word_acc: 0.7969 - val_answer_classifier_acc: 0.2550\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 5.2138 - ignore_last_word_loss: 1.1307 - answer_classifier_loss: 4.0831 - ignore_last_word_acc: 0.7961 - answer_classifier_acc: 0.2538 - val_loss: 6.2627 - val_ignore_last_word_loss: 1.2961 - val_answer_classifier_loss: 4.9666 - val_ignore_last_word_acc: 0.8010 - val_answer_classifier_acc: 0.2550\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 5.2195 - ignore_last_word_loss: 1.1028 - answer_classifier_loss: 4.1167 - ignore_last_word_acc: 0.8033 - answer_classifier_acc: 0.2200 - val_loss: 6.2572 - val_ignore_last_word_loss: 1.2868 - val_answer_classifier_loss: 4.9705 - val_ignore_last_word_acc: 0.8021 - val_answer_classifier_acc: 0.2000\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 25s 31ms/step - loss: 5.1461 - ignore_last_word_loss: 1.0666 - answer_classifier_loss: 4.0795 - ignore_last_word_acc: 0.8076 - answer_classifier_acc: 0.2475 - val_loss: 6.1389 - val_ignore_last_word_loss: 1.2490 - val_answer_classifier_loss: 4.8899 - val_ignore_last_word_acc: 0.8054 - val_answer_classifier_acc: 0.2550\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 23s 28ms/step - loss: 5.0478 - ignore_last_word_loss: 1.0287 - answer_classifier_loss: 4.0191 - ignore_last_word_acc: 0.8136 - answer_classifier_acc: 0.2238 - val_loss: 5.7920 - val_ignore_last_word_loss: 1.2380 - val_answer_classifier_loss: 4.5540 - val_ignore_last_word_acc: 0.8135 - val_answer_classifier_acc: 0.2550\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 4.5818 - ignore_last_word_loss: 1.0010 - answer_classifier_loss: 3.5808 - ignore_last_word_acc: 0.8161 - answer_classifier_acc: 0.2625 - val_loss: 5.2518 - val_ignore_last_word_loss: 1.2023 - val_answer_classifier_loss: 4.0495 - val_ignore_last_word_acc: 0.8196 - val_answer_classifier_acc: 0.2650\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 23s 28ms/step - loss: 4.4192 - ignore_last_word_loss: 0.9655 - answer_classifier_loss: 3.4538 - ignore_last_word_acc: 0.8217 - answer_classifier_acc: 0.2412 - val_loss: 5.7567 - val_ignore_last_word_loss: 1.1861 - val_answer_classifier_loss: 4.5706 - val_ignore_last_word_acc: 0.8213 - val_answer_classifier_acc: 0.2950\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 4.2956 - ignore_last_word_loss: 0.9290 - answer_classifier_loss: 3.3666 - ignore_last_word_acc: 0.8212 - answer_classifier_acc: 0.2587 - val_loss: 5.2286 - val_ignore_last_word_loss: 1.1680 - val_answer_classifier_loss: 4.0606 - val_ignore_last_word_acc: 0.8223 - val_answer_classifier_acc: 0.2950\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 4.1926 - ignore_last_word_loss: 0.9085 - answer_classifier_loss: 3.2841 - ignore_last_word_acc: 0.8213 - answer_classifier_acc: 0.2625 - val_loss: 5.6394 - val_ignore_last_word_loss: 1.1697 - val_answer_classifier_loss: 4.4697 - val_ignore_last_word_acc: 0.8188 - val_answer_classifier_acc: 0.2750\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 4.1143 - ignore_last_word_loss: 0.8935 - answer_classifier_loss: 3.2208 - ignore_last_word_acc: 0.8237 - answer_classifier_acc: 0.2587 - val_loss: 5.7590 - val_ignore_last_word_loss: 1.1637 - val_answer_classifier_loss: 4.5953 - val_ignore_last_word_acc: 0.8223 - val_answer_classifier_acc: 0.2200\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 23s 28ms/step - loss: 3.9462 - ignore_last_word_loss: 0.8702 - answer_classifier_loss: 3.0759 - ignore_last_word_acc: 0.8245 - answer_classifier_acc: 0.2800 - val_loss: 4.7494 - val_ignore_last_word_loss: 1.1653 - val_answer_classifier_loss: 3.5841 - val_ignore_last_word_acc: 0.8210 - val_answer_classifier_acc: 0.3000\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 3.7778 - ignore_last_word_loss: 0.8523 - answer_classifier_loss: 2.9254 - ignore_last_word_acc: 0.8259 - answer_classifier_acc: 0.2737 - val_loss: 4.9387 - val_ignore_last_word_loss: 1.1590 - val_answer_classifier_loss: 3.7797 - val_ignore_last_word_acc: 0.8231 - val_answer_classifier_acc: 0.3050\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 3.7002 - ignore_last_word_loss: 0.8329 - answer_classifier_loss: 2.8673 - ignore_last_word_acc: 0.8269 - answer_classifier_acc: 0.2863 - val_loss: 5.3902 - val_ignore_last_word_loss: 1.1715 - val_answer_classifier_loss: 4.2187 - val_ignore_last_word_acc: 0.8240 - val_answer_classifier_acc: 0.2400\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 3.6431 - ignore_last_word_loss: 0.8257 - answer_classifier_loss: 2.8174 - ignore_last_word_acc: 0.8277 - answer_classifier_acc: 0.2775 - val_loss: 4.7593 - val_ignore_last_word_loss: 1.1522 - val_answer_classifier_loss: 3.6071 - val_ignore_last_word_acc: 0.8244 - val_answer_classifier_acc: 0.3000\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 3.5052 - ignore_last_word_loss: 0.8039 - answer_classifier_loss: 2.7013 - ignore_last_word_acc: 0.8283 - answer_classifier_acc: 0.2800 - val_loss: 5.0776 - val_ignore_last_word_loss: 1.1507 - val_answer_classifier_loss: 3.9269 - val_ignore_last_word_acc: 0.8231 - val_answer_classifier_acc: 0.2950\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 3.4423 - ignore_last_word_loss: 0.7871 - answer_classifier_loss: 2.6552 - ignore_last_word_acc: 0.8305 - answer_classifier_acc: 0.2850 - val_loss: 4.8452 - val_ignore_last_word_loss: 1.1566 - val_answer_classifier_loss: 3.6886 - val_ignore_last_word_acc: 0.8269 - val_answer_classifier_acc: 0.2950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 3.3337 - ignore_last_word_loss: 0.7745 - answer_classifier_loss: 2.5592 - ignore_last_word_acc: 0.8310 - answer_classifier_acc: 0.3212 - val_loss: 4.9225 - val_ignore_last_word_loss: 1.1562 - val_answer_classifier_loss: 3.7664 - val_ignore_last_word_acc: 0.8263 - val_answer_classifier_acc: 0.3100\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 3.3194 - ignore_last_word_loss: 0.7656 - answer_classifier_loss: 2.5539 - ignore_last_word_acc: 0.8312 - answer_classifier_acc: 0.3038 - val_loss: 5.1988 - val_ignore_last_word_loss: 1.1698 - val_answer_classifier_loss: 4.0289 - val_ignore_last_word_acc: 0.8252 - val_answer_classifier_acc: 0.2600\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 3.2735 - ignore_last_word_loss: 0.7604 - answer_classifier_loss: 2.5131 - ignore_last_word_acc: 0.8307 - answer_classifier_acc: 0.2888 - val_loss: 4.9524 - val_ignore_last_word_loss: 1.1580 - val_answer_classifier_loss: 3.7944 - val_ignore_last_word_acc: 0.8256 - val_answer_classifier_acc: 0.3150\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 23s 28ms/step - loss: 3.1060 - ignore_last_word_loss: 0.7441 - answer_classifier_loss: 2.3619 - ignore_last_word_acc: 0.8328 - answer_classifier_acc: 0.3387 - val_loss: 5.4631 - val_ignore_last_word_loss: 1.1600 - val_answer_classifier_loss: 4.3032 - val_ignore_last_word_acc: 0.8256 - val_answer_classifier_acc: 0.2900\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 3.0085 - ignore_last_word_loss: 0.7301 - answer_classifier_loss: 2.2784 - ignore_last_word_acc: 0.8318 - answer_classifier_acc: 0.3625 - val_loss: 5.2173 - val_ignore_last_word_loss: 1.1628 - val_answer_classifier_loss: 4.0546 - val_ignore_last_word_acc: 0.8275 - val_answer_classifier_acc: 0.3100\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 3.0185 - ignore_last_word_loss: 0.7253 - answer_classifier_loss: 2.2932 - ignore_last_word_acc: 0.8338 - answer_classifier_acc: 0.3463 - val_loss: 5.5005 - val_ignore_last_word_loss: 1.1663 - val_answer_classifier_loss: 4.3342 - val_ignore_last_word_acc: 0.8252 - val_answer_classifier_acc: 0.3100\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 2.9885 - ignore_last_word_loss: 0.7244 - answer_classifier_loss: 2.2641 - ignore_last_word_acc: 0.8350 - answer_classifier_acc: 0.3800 - val_loss: 5.6969 - val_ignore_last_word_loss: 1.1644 - val_answer_classifier_loss: 4.5324 - val_ignore_last_word_acc: 0.8250 - val_answer_classifier_acc: 0.2900\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 23s 28ms/step - loss: 2.8407 - ignore_last_word_loss: 0.7138 - answer_classifier_loss: 2.1269 - ignore_last_word_acc: 0.8346 - answer_classifier_acc: 0.4200 - val_loss: 5.7386 - val_ignore_last_word_loss: 1.1619 - val_answer_classifier_loss: 4.5767 - val_ignore_last_word_acc: 0.8267 - val_answer_classifier_acc: 0.2800\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 2.7205 - ignore_last_word_loss: 0.7071 - answer_classifier_loss: 2.0134 - ignore_last_word_acc: 0.8337 - answer_classifier_acc: 0.4600 - val_loss: 5.6519 - val_ignore_last_word_loss: 1.1563 - val_answer_classifier_loss: 4.4956 - val_ignore_last_word_acc: 0.8277 - val_answer_classifier_acc: 0.3300\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 2.5604 - ignore_last_word_loss: 0.6965 - answer_classifier_loss: 1.8639 - ignore_last_word_acc: 0.8357 - answer_classifier_acc: 0.4775 - val_loss: 5.3366 - val_ignore_last_word_loss: 1.1689 - val_answer_classifier_loss: 4.1677 - val_ignore_last_word_acc: 0.8283 - val_answer_classifier_acc: 0.3200\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 2.5176 - ignore_last_word_loss: 0.6930 - answer_classifier_loss: 1.8245 - ignore_last_word_acc: 0.8361 - answer_classifier_acc: 0.5075 - val_loss: 5.9641 - val_ignore_last_word_loss: 1.1651 - val_answer_classifier_loss: 4.7991 - val_ignore_last_word_acc: 0.8258 - val_answer_classifier_acc: 0.3100\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 2.3304 - ignore_last_word_loss: 0.6828 - answer_classifier_loss: 1.6477 - ignore_last_word_acc: 0.8363 - answer_classifier_acc: 0.5225 - val_loss: 6.2249 - val_ignore_last_word_loss: 1.1633 - val_answer_classifier_loss: 5.0616 - val_ignore_last_word_acc: 0.8275 - val_answer_classifier_acc: 0.3000\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 2.2777 - ignore_last_word_loss: 0.6749 - answer_classifier_loss: 1.6028 - ignore_last_word_acc: 0.8386 - answer_classifier_acc: 0.5350 - val_loss: 5.6285 - val_ignore_last_word_loss: 1.1669 - val_answer_classifier_loss: 4.4616 - val_ignore_last_word_acc: 0.8242 - val_answer_classifier_acc: 0.3100\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 23s 28ms/step - loss: 2.2433 - ignore_last_word_loss: 0.6709 - answer_classifier_loss: 1.5724 - ignore_last_word_acc: 0.8369 - answer_classifier_acc: 0.5350 - val_loss: 6.5094 - val_ignore_last_word_loss: 1.1728 - val_answer_classifier_loss: 5.3366 - val_ignore_last_word_acc: 0.8267 - val_answer_classifier_acc: 0.3050\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 2.1003 - ignore_last_word_loss: 0.6619 - answer_classifier_loss: 1.4385 - ignore_last_word_acc: 0.8408 - answer_classifier_acc: 0.5675 - val_loss: 6.4363 - val_ignore_last_word_loss: 1.1704 - val_answer_classifier_loss: 5.2659 - val_ignore_last_word_acc: 0.8240 - val_answer_classifier_acc: 0.2900\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 2.0003 - ignore_last_word_loss: 0.6468 - answer_classifier_loss: 1.3535 - ignore_last_word_acc: 0.8393 - answer_classifier_acc: 0.5988 - val_loss: 6.3637 - val_ignore_last_word_loss: 1.1754 - val_answer_classifier_loss: 5.1883 - val_ignore_last_word_acc: 0.8262 - val_answer_classifier_acc: 0.2950\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 1.8251 - ignore_last_word_loss: 0.6401 - answer_classifier_loss: 1.1851 - ignore_last_word_acc: 0.8410 - answer_classifier_acc: 0.6212 - val_loss: 6.5201 - val_ignore_last_word_loss: 1.1853 - val_answer_classifier_loss: 5.3348 - val_ignore_last_word_acc: 0.8244 - val_answer_classifier_acc: 0.2950\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 1.8029 - ignore_last_word_loss: 0.6365 - answer_classifier_loss: 1.1664 - ignore_last_word_acc: 0.8418 - answer_classifier_acc: 0.6550 - val_loss: 6.9346 - val_ignore_last_word_loss: 1.1926 - val_answer_classifier_loss: 5.7421 - val_ignore_last_word_acc: 0.8225 - val_answer_classifier_acc: 0.2800\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 1.7334 - ignore_last_word_loss: 0.6311 - answer_classifier_loss: 1.1023 - ignore_last_word_acc: 0.8430 - answer_classifier_acc: 0.6588 - val_loss: 6.8874 - val_ignore_last_word_loss: 1.1898 - val_answer_classifier_loss: 5.6977 - val_ignore_last_word_acc: 0.8254 - val_answer_classifier_acc: 0.2800\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 23s 28ms/step - loss: 1.7112 - ignore_last_word_loss: 0.6287 - answer_classifier_loss: 1.0825 - ignore_last_word_acc: 0.8418 - answer_classifier_acc: 0.6575 - val_loss: 6.9515 - val_ignore_last_word_loss: 1.1876 - val_answer_classifier_loss: 5.7638 - val_ignore_last_word_acc: 0.8275 - val_answer_classifier_acc: 0.2900\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 1.5402 - ignore_last_word_loss: 0.6185 - answer_classifier_loss: 0.9217 - ignore_last_word_acc: 0.8464 - answer_classifier_acc: 0.7150 - val_loss: 7.4339 - val_ignore_last_word_loss: 1.1867 - val_answer_classifier_loss: 6.2472 - val_ignore_last_word_acc: 0.8281 - val_answer_classifier_acc: 0.3050\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 1.4421 - ignore_last_word_loss: 0.6089 - answer_classifier_loss: 0.8332 - ignore_last_word_acc: 0.8474 - answer_classifier_acc: 0.7213 - val_loss: 7.4721 - val_ignore_last_word_loss: 1.1938 - val_answer_classifier_loss: 6.2783 - val_ignore_last_word_acc: 0.8242 - val_answer_classifier_acc: 0.3050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 1.4018 - ignore_last_word_loss: 0.6040 - answer_classifier_loss: 0.7978 - ignore_last_word_acc: 0.8483 - answer_classifier_acc: 0.7475 - val_loss: 7.5991 - val_ignore_last_word_loss: 1.1894 - val_answer_classifier_loss: 6.4097 - val_ignore_last_word_acc: 0.8250 - val_answer_classifier_acc: 0.3200\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 1.4196 - ignore_last_word_loss: 0.5966 - answer_classifier_loss: 0.8230 - ignore_last_word_acc: 0.8498 - answer_classifier_acc: 0.7425 - val_loss: 7.5226 - val_ignore_last_word_loss: 1.1992 - val_answer_classifier_loss: 6.3235 - val_ignore_last_word_acc: 0.8256 - val_answer_classifier_acc: 0.3000\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 1.3063 - ignore_last_word_loss: 0.5918 - answer_classifier_loss: 0.7145 - ignore_last_word_acc: 0.8513 - answer_classifier_acc: 0.7600 - val_loss: 7.9823 - val_ignore_last_word_loss: 1.1959 - val_answer_classifier_loss: 6.7863 - val_ignore_last_word_acc: 0.8279 - val_answer_classifier_acc: 0.2700\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 1.2613 - ignore_last_word_loss: 0.5884 - answer_classifier_loss: 0.6730 - ignore_last_word_acc: 0.8495 - answer_classifier_acc: 0.7688 - val_loss: 7.7364 - val_ignore_last_word_loss: 1.1920 - val_answer_classifier_loss: 6.5444 - val_ignore_last_word_acc: 0.8288 - val_answer_classifier_acc: 0.3000\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 1.1988 - ignore_last_word_loss: 0.5824 - answer_classifier_loss: 0.6164 - ignore_last_word_acc: 0.8525 - answer_classifier_acc: 0.7963 - val_loss: 7.8150 - val_ignore_last_word_loss: 1.1936 - val_answer_classifier_loss: 6.6214 - val_ignore_last_word_acc: 0.8263 - val_answer_classifier_acc: 0.3250\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 1.1011 - ignore_last_word_loss: 0.5731 - answer_classifier_loss: 0.5280 - ignore_last_word_acc: 0.8537 - answer_classifier_acc: 0.8325 - val_loss: 7.8699 - val_ignore_last_word_loss: 1.2008 - val_answer_classifier_loss: 6.6690 - val_ignore_last_word_acc: 0.8288 - val_answer_classifier_acc: 0.3300\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 1.0626 - ignore_last_word_loss: 0.5700 - answer_classifier_loss: 0.4926 - ignore_last_word_acc: 0.8544 - answer_classifier_acc: 0.8412 - val_loss: 8.0383 - val_ignore_last_word_loss: 1.2003 - val_answer_classifier_loss: 6.8380 - val_ignore_last_word_acc: 0.8271 - val_answer_classifier_acc: 0.3150\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 1.0619 - ignore_last_word_loss: 0.5657 - answer_classifier_loss: 0.4962 - ignore_last_word_acc: 0.8552 - answer_classifier_acc: 0.8412 - val_loss: 8.1975 - val_ignore_last_word_loss: 1.2111 - val_answer_classifier_loss: 6.9864 - val_ignore_last_word_acc: 0.8275 - val_answer_classifier_acc: 0.2800\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 0.9742 - ignore_last_word_loss: 0.5562 - answer_classifier_loss: 0.4180 - ignore_last_word_acc: 0.8559 - answer_classifier_acc: 0.8612 - val_loss: 8.3419 - val_ignore_last_word_loss: 1.2114 - val_answer_classifier_loss: 7.1304 - val_ignore_last_word_acc: 0.8273 - val_answer_classifier_acc: 0.2950\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 0.8703 - ignore_last_word_loss: 0.5460 - answer_classifier_loss: 0.3243 - ignore_last_word_acc: 0.8570 - answer_classifier_acc: 0.8900 - val_loss: 8.2424 - val_ignore_last_word_loss: 1.2082 - val_answer_classifier_loss: 7.0342 - val_ignore_last_word_acc: 0.8242 - val_answer_classifier_acc: 0.3250\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.8513 - ignore_last_word_loss: 0.5404 - answer_classifier_loss: 0.3109 - ignore_last_word_acc: 0.8578 - answer_classifier_acc: 0.9000 - val_loss: 8.5907 - val_ignore_last_word_loss: 1.2089 - val_answer_classifier_loss: 7.3819 - val_ignore_last_word_acc: 0.8258 - val_answer_classifier_acc: 0.3150\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 0.8133 - ignore_last_word_loss: 0.5312 - answer_classifier_loss: 0.2822 - ignore_last_word_acc: 0.8609 - answer_classifier_acc: 0.9062 - val_loss: 8.5482 - val_ignore_last_word_loss: 1.2117 - val_answer_classifier_loss: 7.3365 - val_ignore_last_word_acc: 0.8252 - val_answer_classifier_acc: 0.3100\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.7973 - ignore_last_word_loss: 0.5250 - answer_classifier_loss: 0.2723 - ignore_last_word_acc: 0.8611 - answer_classifier_acc: 0.9150 - val_loss: 8.3973 - val_ignore_last_word_loss: 1.2135 - val_answer_classifier_loss: 7.1838 - val_ignore_last_word_acc: 0.8250 - val_answer_classifier_acc: 0.3250\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 0.7648 - ignore_last_word_loss: 0.5182 - answer_classifier_loss: 0.2466 - ignore_last_word_acc: 0.8634 - answer_classifier_acc: 0.9225 - val_loss: 8.7135 - val_ignore_last_word_loss: 1.2147 - val_answer_classifier_loss: 7.4988 - val_ignore_last_word_acc: 0.8262 - val_answer_classifier_acc: 0.3100\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.7962 - ignore_last_word_loss: 0.5145 - answer_classifier_loss: 0.2817 - ignore_last_word_acc: 0.8646 - answer_classifier_acc: 0.9075 - val_loss: 8.7625 - val_ignore_last_word_loss: 1.2223 - val_answer_classifier_loss: 7.5402 - val_ignore_last_word_acc: 0.8263 - val_answer_classifier_acc: 0.3200\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.7579 - ignore_last_word_loss: 0.5112 - answer_classifier_loss: 0.2467 - ignore_last_word_acc: 0.8640 - answer_classifier_acc: 0.9263 - val_loss: 8.6946 - val_ignore_last_word_loss: 1.2191 - val_answer_classifier_loss: 7.4755 - val_ignore_last_word_acc: 0.8233 - val_answer_classifier_acc: 0.3050\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.7613 - ignore_last_word_loss: 0.5071 - answer_classifier_loss: 0.2543 - ignore_last_word_acc: 0.8648 - answer_classifier_acc: 0.9225 - val_loss: 8.9212 - val_ignore_last_word_loss: 1.2258 - val_answer_classifier_loss: 7.6954 - val_ignore_last_word_acc: 0.8265 - val_answer_classifier_acc: 0.3000\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.7363 - ignore_last_word_loss: 0.4999 - answer_classifier_loss: 0.2364 - ignore_last_word_acc: 0.8675 - answer_classifier_acc: 0.9288 - val_loss: 8.6524 - val_ignore_last_word_loss: 1.2326 - val_answer_classifier_loss: 7.4198 - val_ignore_last_word_acc: 0.8244 - val_answer_classifier_acc: 0.3300\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 0.7766 - ignore_last_word_loss: 0.4978 - answer_classifier_loss: 0.2788 - ignore_last_word_acc: 0.8662 - answer_classifier_acc: 0.9075 - val_loss: 8.6672 - val_ignore_last_word_loss: 1.2252 - val_answer_classifier_loss: 7.4420 - val_ignore_last_word_acc: 0.8254 - val_answer_classifier_acc: 0.3050\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.7791 - ignore_last_word_loss: 0.4985 - answer_classifier_loss: 0.2806 - ignore_last_word_acc: 0.8666 - answer_classifier_acc: 0.9175 - val_loss: 8.6200 - val_ignore_last_word_loss: 1.2261 - val_answer_classifier_loss: 7.3939 - val_ignore_last_word_acc: 0.8248 - val_answer_classifier_acc: 0.3200\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 0.8244 - ignore_last_word_loss: 0.4951 - answer_classifier_loss: 0.3293 - ignore_last_word_acc: 0.8676 - answer_classifier_acc: 0.8987 - val_loss: 9.2441 - val_ignore_last_word_loss: 1.2328 - val_answer_classifier_loss: 8.0113 - val_ignore_last_word_acc: 0.8227 - val_answer_classifier_acc: 0.3000\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 0.8978 - ignore_last_word_loss: 0.4919 - answer_classifier_loss: 0.4058 - ignore_last_word_acc: 0.8675 - answer_classifier_acc: 0.8725 - val_loss: 8.8995 - val_ignore_last_word_loss: 1.2250 - val_answer_classifier_loss: 7.6746 - val_ignore_last_word_acc: 0.8233 - val_answer_classifier_acc: 0.3200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.8487 - ignore_last_word_loss: 0.4924 - answer_classifier_loss: 0.3563 - ignore_last_word_acc: 0.8674 - answer_classifier_acc: 0.8900 - val_loss: 9.2140 - val_ignore_last_word_loss: 1.2257 - val_answer_classifier_loss: 7.9883 - val_ignore_last_word_acc: 0.8237 - val_answer_classifier_acc: 0.2650\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 0.7381 - ignore_last_word_loss: 0.4904 - answer_classifier_loss: 0.2477 - ignore_last_word_acc: 0.8697 - answer_classifier_acc: 0.9138 - val_loss: 8.9905 - val_ignore_last_word_loss: 1.2295 - val_answer_classifier_loss: 7.7609 - val_ignore_last_word_acc: 0.8246 - val_answer_classifier_acc: 0.3050\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.7227 - ignore_last_word_loss: 0.4818 - answer_classifier_loss: 0.2409 - ignore_last_word_acc: 0.8697 - answer_classifier_acc: 0.9200 - val_loss: 8.8747 - val_ignore_last_word_loss: 1.2338 - val_answer_classifier_loss: 7.6408 - val_ignore_last_word_acc: 0.8260 - val_answer_classifier_acc: 0.3150\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.6619 - ignore_last_word_loss: 0.4748 - answer_classifier_loss: 0.1870 - ignore_last_word_acc: 0.8723 - answer_classifier_acc: 0.9425 - val_loss: 9.0564 - val_ignore_last_word_loss: 1.2281 - val_answer_classifier_loss: 7.8283 - val_ignore_last_word_acc: 0.8273 - val_answer_classifier_acc: 0.3250\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.7323 - ignore_last_word_loss: 0.4668 - answer_classifier_loss: 0.2655 - ignore_last_word_acc: 0.8741 - answer_classifier_acc: 0.9200 - val_loss: 9.2906 - val_ignore_last_word_loss: 1.2327 - val_answer_classifier_loss: 8.0579 - val_ignore_last_word_acc: 0.8250 - val_answer_classifier_acc: 0.3050\n",
      "Epoch 72/100\n",
      "544/800 [===================>..........] - ETA: 6s - loss: 0.7861 - ignore_last_word_loss: 0.4648 - answer_classifier_loss: 0.3213 - ignore_last_word_acc: 0.8742 - answer_classifier_acc: 0.9026"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-154d4b2f05d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0my_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             epochs=epochs)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-17174d8c780b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, y_train, x_val, y_val, batch_size, epochs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                        \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                        shuffle=True)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
=======
     "ename": "ValueError",
     "evalue": "Error when checking target: expected ignore_last_word to have shape (25, 12602) but got array with shape (26, 12602)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-70897ddd6739>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0my_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             epochs=epochs)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-12a4ed71e890>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, y_train, x_val, y_val, batch_size, epochs)\u001b[0m\n\u001b[1;32m     73\u001b[0m                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                        \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                        shuffle=True)\n\u001b[0m",
      "\u001b[0;32m~/CMU/Fall-18/Internships/Tensorflow/tfenv/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps_per_epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1536\u001b[0;31m         validation_split=validation_split)\n\u001b[0m\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CMU/Fall-18/Internships/Tensorflow/tfenv/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     x, y, sample_weights = self._standardize_weights(x, y, sample_weight,\n\u001b[0;32m--> 992\u001b[0;31m                                                      class_weight, batch_size)\n\u001b[0m\u001b[1;32m    993\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CMU/Fall-18/Internships/Tensorflow/tfenv/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   1152\u001b[0m           \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m           exception_prefix='target')\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m       \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CMU/Fall-18/Internships/Tensorflow/tfenv/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;34m'Error when checking '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                 ' but got array with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    333\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected ignore_last_word to have shape (25, 12602) but got array with shape (26, 12602)"
>>>>>>> 7e28458e9f3e47030b8d168f4cd8eb5baab69e42
     ]
    }
   ],
   "source": [
    "ques = h5.File(\"../../data/data_train_val/data_prepro.h5\", \"r\")\n",
    "ques_train = ques['ques_train'][:n_train]\n",
    "ques_to_image_train = ques['img_pos_train'][:n_train] - 1\n",
    "\n",
    "ans_train = tf.keras.utils.to_categorical(y=ques['answers'][:n_train],\n",
    "                                          num_classes=n_answers)\n",
    "\n",
    "img_feat = h5.File(\"../../data/data_train_val/data_img.h5\", \"r\")\n",
    "img_train = np.array(img_feat['images_train'])[ques_to_image_train]\n",
    "\n",
    "print(img_train.shape)\n",
    "\n",
    "model = VQANet(combine_type='feed_CNN_to_all', \n",
    "               question_embed_dim=question_embed_dim, \n",
    "               lstm_dim=lstm_dim, \n",
    "               n_answers=n_answers)\n",
    "\n",
    "print(model.model.summary())\n",
    "\n",
    "model.train(x_train=[img_train, ques_train], \n",
    "            y_train=[tf.keras.utils.to_categorical(y=ques_train, num_classes=VOCAB_SIZE), ans_train], \n",
    "            x_val=[], \n",
    "            y_val=[], \n",
    "            batch_size=batch_size, \n",
    "            epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
