{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import h5py as h5\n",
    "import keras.backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 12602\n",
    "MAX_QUESTION_LEN = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQANet:\n",
    "    def __init__(self, combine_type, question_embed_dim, lstm_dim, n_answers):\n",
    "        self.combine_type = combine_type\n",
    "        self.question_embed_dim = question_embed_dim\n",
    "        self.lstm_dim = lstm_dim\n",
    "        self.n_answers = n_answers\n",
    "        self.build()\n",
    "        \n",
    "    def build(self):\n",
    "        \n",
    "        image_features = tf.keras.layers.Input(shape=(4096,), \n",
    "                                                   dtype='float32')\n",
    "            \n",
    "        image_embedding = tf.keras.layers.Dense(units=self.question_embed_dim, \n",
    "                                                activation='elu',\n",
    "                                                name='image_embedding')(inputs=image_features)\n",
    "        \n",
    "        if self.combine_type == 'show_and_tell':\n",
    "            concat_axis = 1\n",
    "            image_embedding = tf.keras.layers.Reshape((1, self.question_embed_dim))(image_embedding)\n",
    "        elif self.combine_type == 'feed_CNN_to_all':\n",
    "            concat_axis = -1\n",
    "            image_embedding = tf.keras.layers.RepeatVector(MAX_QUESTION_LEN)(image_embedding)\n",
    "            \n",
    "        question_input = tf.keras.layers.Input(shape=(MAX_QUESTION_LEN,), \n",
    "                                               dtype='int32',\n",
    "                                               name='question_input')\n",
    "\n",
    "        question_embedding = tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, \n",
    "                                                       output_dim=self.question_embed_dim, \n",
    "                                                       input_length=MAX_QUESTION_LEN,\n",
    "                                                       name='question_embedding')(inputs=question_input)\n",
    "\n",
    "        image_question_embedding = tf.keras.layers.Concatenate(axis=concat_axis, \n",
    "                                                               name='image_question_embedding')(inputs=[image_embedding, question_embedding])\n",
    "\n",
    "        question_features, last_h, _ = tf.keras.layers.LSTM(units=self.lstm_dim, \n",
    "                                                            return_sequences=True, \n",
    "                                                            return_state=True, \n",
    "                                                            name='question_generator')(inputs=image_question_embedding)\n",
    "\n",
    "        question_pred = tf.keras.layers.TimeDistributed(layer=tf.keras.layers.Dense(units=VOCAB_SIZE, \n",
    "                                                                                    activation='softmax', \n",
    "                                                                                    name='word_classifier'))(inputs=question_features)\n",
    "\n",
    "        if self.combine_type == 'show_and_tell':\n",
    "            question_pred = tf.keras.layers.Lambda(lambda x: x[:, :-1, :], \n",
    "                                                   name='ignore_last_word')(inputs=question_pred)\n",
    "\n",
    "        answer_fc1 = tf.keras.layers.Dense(units=1000,\n",
    "                                            activation='elu',\n",
    "                                            name='answer_dense_1')(inputs=last_h)\n",
    "\n",
    "        answer_fc2 = tf.keras.layers.Dense(units=1000,\n",
    "                                            activation='elu',\n",
    "                                            name='answer_dense_2')(inputs=answer_fc1)\n",
    "\n",
    "        answer_pred = tf.keras.layers.Dense(units=self.n_answers,\n",
    "                                            activation='softmax',\n",
    "                                            name='answer_classifier')(inputs=answer_fc2)\n",
    "\n",
    "        self.model = tf.keras.Model(inputs=[image_features, question_input], \n",
    "                                    outputs=[question_pred, answer_pred])  \n",
    "\n",
    "        self.model.compile(loss='categorical_crossentropy', \n",
    "                           optimizer='adam', metrics=['accuracy'])\n",
    "            \n",
    "    \n",
    "    def train(self, x_train, y_train, x_val, y_val, batch_size, epochs):\n",
    "        self.model.fit(x=x_train, \n",
    "                       y=y_train, \n",
    "                       batch_size=batch_size, \n",
    "                       epochs=epochs, \n",
    "                       verbose=1,\n",
    "                       validation_split=0.2,\n",
    "                       shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "question_embed_dim = 256\n",
    "lstm_dim = 512\n",
    "n_answers = 1000\n",
    "n_train = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4096)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 4096)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_embedding (Dense)         (None, 256)          1048832     input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "question_input (InputLayer)     (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 26, 256)      0           image_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "question_embedding (Embedding)  (None, 26, 256)      3226112     question_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "image_question_embedding (Conca (None, 26, 512)      0           repeat_vector[0][0]              \n",
      "                                                                 question_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "question_generator (LSTM)       [(None, 26, 512), (N 2099200     image_question_embedding[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "answer_dense_1 (Dense)          (None, 1000)         513000      question_generator[0][1]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 26, 12602)    6464826     question_generator[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "answer_dense_2 (Dense)          (None, 1000)         1001000     answer_dense_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "ignore_last_word (Lambda)       (None, 25, 12602)    0           time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "answer_classifier (Dense)       (None, 1000)         1001000     answer_dense_2[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 15,353,970\n",
      "Trainable params: 15,353,970\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected ignore_last_word to have shape (25, 12602) but got array with shape (26, 12602)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-70897ddd6739>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0my_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             epochs=epochs)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-12a4ed71e890>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, y_train, x_val, y_val, batch_size, epochs)\u001b[0m\n\u001b[1;32m     73\u001b[0m                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                        \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                        shuffle=True)\n\u001b[0m",
      "\u001b[0;32m~/CMU/Fall-18/Internships/Tensorflow/tfenv/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps_per_epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1536\u001b[0;31m         validation_split=validation_split)\n\u001b[0m\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CMU/Fall-18/Internships/Tensorflow/tfenv/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     x, y, sample_weights = self._standardize_weights(x, y, sample_weight,\n\u001b[0;32m--> 992\u001b[0;31m                                                      class_weight, batch_size)\n\u001b[0m\u001b[1;32m    993\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CMU/Fall-18/Internships/Tensorflow/tfenv/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   1152\u001b[0m           \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m           exception_prefix='target')\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m       \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CMU/Fall-18/Internships/Tensorflow/tfenv/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;34m'Error when checking '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                 ' but got array with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    333\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected ignore_last_word to have shape (25, 12602) but got array with shape (26, 12602)"
     ]
    }
   ],
   "source": [
    "ques = h5.File(\"../../data/data_train_val/data_prepro.h5\", \"r\")\n",
    "ques_train = ques['ques_train'][:n_train]\n",
    "ques_to_image_train = ques['img_pos_train'][:n_train] - 1\n",
    "\n",
    "ans_train = tf.keras.utils.to_categorical(y=ques['answers'][:n_train],\n",
    "                                          num_classes=n_answers)\n",
    "\n",
    "img_feat = h5.File(\"../../data/data_train_val/data_img.h5\", \"r\")\n",
    "img_train = np.array(img_feat['images_train'])[ques_to_image_train]\n",
    "\n",
    "print(img_train.shape)\n",
    "\n",
    "model = VQANet(combine_type='feed_CNN_to_all', \n",
    "               question_embed_dim=question_embed_dim, \n",
    "               lstm_dim=lstm_dim, \n",
    "               n_answers=n_answers)\n",
    "\n",
    "print(model.model.summary())\n",
    "\n",
    "model.train(x_train=[img_train, ques_train], \n",
    "            y_train=[tf.keras.utils.to_categorical(y=ques_train, num_classes=VOCAB_SIZE), ans_train], \n",
    "            x_val=[], \n",
    "            y_val=[], \n",
    "            batch_size=batch_size, \n",
    "            epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
