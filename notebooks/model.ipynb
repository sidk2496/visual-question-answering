{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import h5py as h5\n",
    "import keras.backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 12602\n",
    "MAX_QUESTION_LEN = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQANet:\n",
    "    def __init__(self, combine_type, question_embed_dim, lstm_dim, n_answers):\n",
    "        self.combine_type = combine_type\n",
    "        self.question_embed_dim = question_embed_dim\n",
    "        self.lstm_dim = lstm_dim\n",
    "        self.n_answers = n_answers\n",
    "        self.build()\n",
    "        \n",
    "    def build(self):\n",
    "        \n",
    "        image_features = tf.keras.layers.Input(shape=(4096,), \n",
    "                                                   dtype='float32')\n",
    "            \n",
    "        image_embedding = tf.keras.layers.Dense(units=self.question_embed_dim, \n",
    "                                                activation='elu',\n",
    "                                                name='image_embedding')(inputs=image_features)\n",
    "        \n",
    "        if self.combine_type == 'show_and_tell':\n",
    "            concat_axis = 1\n",
    "            image_embedding = tf.keras.layers.Reshape((1, self.question_embed_dim))(inputs=image_embedding)\n",
    "        elif self.combine_type == 'feed_CNN_to_all':\n",
    "            concat_axis = -1\n",
    "            image_embedding = tf.keras.layers.RepeatVector(MAX_QUESTION_LEN)(inputs=image_embedding)\n",
    "            \n",
    "        question_input = tf.keras.layers.Input(shape=(MAX_QUESTION_LEN,), \n",
    "                                               dtype='int32',\n",
    "                                               name='question_input')\n",
    "\n",
    "        question_embedding = tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, \n",
    "                                                       output_dim=self.question_embed_dim, \n",
    "                                                       input_length=MAX_QUESTION_LEN,\n",
    "                                                       name='question_embedding')(inputs=question_input)\n",
    "\n",
    "        image_question_embedding = tf.keras.layers.Concatenate(axis=concat_axis, \n",
    "                                                               name='image_question_embedding')(inputs=[image_embedding, question_embedding])\n",
    "\n",
    "        question_features, last_h, _ = tf.keras.layers.LSTM(units=self.lstm_dim, \n",
    "                                                            return_sequences=True, \n",
    "                                                            return_state=True, \n",
    "                                                            name='question_generator')(inputs=image_question_embedding)\n",
    "\n",
    "        question_pred = tf.keras.layers.TimeDistributed(layer=tf.keras.layers.Dense(units=VOCAB_SIZE, \n",
    "                                                                                    activation='softmax', \n",
    "                                                                                    name='word_classifier'))(inputs=question_features)\n",
    "\n",
    "        if self.combine_type == 'show_and_tell':\n",
    "            question_pred = tf.keras.layers.Lambda(lambda x: x[:, :-1, :], \n",
    "                                                   name='ignore_last_word')(inputs=question_pred)\n",
    "\n",
    "        answer_fc1 = tf.keras.layers.Dense(units=1000,\n",
    "                                            activation='elu',\n",
    "                                            name='answer_dense_1')(inputs=last_h)\n",
    "\n",
    "        answer_fc2 = tf.keras.layers.Dense(units=1000,\n",
    "                                            activation='elu',\n",
    "                                            name='answer_dense_2')(inputs=answer_fc1)\n",
    "\n",
    "        answer_pred = tf.keras.layers.Dense(units=self.n_answers,\n",
    "                                            activation='softmax',\n",
    "                                            name='answer_classifier')(inputs=answer_fc2)\n",
    "\n",
    "        self.model = tf.keras.Model(inputs=[image_features, question_input], \n",
    "                                    outputs=[question_pred, answer_pred])  \n",
    "\n",
    "        self.model.compile(loss='categorical_crossentropy', \n",
    "                           optimizer='adam', metrics=['accuracy'])\n",
    "            \n",
    "    \n",
    "    def train(self, x_train, y_train, x_val, y_val, batch_size, epochs):\n",
    "        self.model.fit(x=x_train, \n",
    "                       y=y_train, \n",
    "                       batch_size=batch_size, \n",
    "                       epochs=epochs, \n",
    "                       verbose=1,\n",
    "                       validation_split=0.2,\n",
    "                       shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "question_embed_dim = 256\n",
    "lstm_dim = 512\n",
    "n_answers = 1000\n",
    "n_train = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4096)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 4096)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_embedding (Dense)         (None, 256)          1048832     input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "question_input (InputLayer)     (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 26, 256)      0           image_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "question_embedding (Embedding)  (None, 26, 256)      3226112     question_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "image_question_embedding (Conca (None, 26, 512)      0           repeat_vector_1[0][0]            \n",
      "                                                                 question_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "question_generator (LSTM)       [(None, 26, 512), (N 2099200     image_question_embedding[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "answer_dense_1 (Dense)          (None, 1000)         513000      question_generator[0][1]         \n",
      "__________________________________________________________________________________________________\n",
      "answer_dense_2 (Dense)          (None, 1000)         1001000     answer_dense_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 26, 12602)    6464826     question_generator[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "answer_classifier (Dense)       (None, 1000)         1001000     answer_dense_2[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 15,353,970\n",
      "Trainable params: 15,353,970\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vignesh2496/CMU/Fall-18/Internships/Tensorflow/tfenv/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 37s 46ms/step - loss: 9.3561 - time_distributed_5_loss: 4.1194 - answer_classifier_loss: 5.2367 - time_distributed_5_acc: 0.6878 - answer_classifier_acc: 0.2162 - val_loss: 6.7785 - val_time_distributed_5_loss: 2.0548 - val_answer_classifier_loss: 4.7238 - val_time_distributed_5_acc: 0.7294 - val_answer_classifier_acc: 0.2000\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 30s 38ms/step - loss: 6.2800 - time_distributed_5_loss: 1.9346 - answer_classifier_loss: 4.3453 - time_distributed_5_acc: 0.7209 - answer_classifier_acc: 0.2137 - val_loss: 6.7366 - val_time_distributed_5_loss: 1.9944 - val_answer_classifier_loss: 4.7423 - val_time_distributed_5_acc: 0.7294 - val_answer_classifier_acc: 0.2550\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 30s 38ms/step - loss: 6.1306 - time_distributed_5_loss: 1.8777 - answer_classifier_loss: 4.2529 - time_distributed_5_acc: 0.7209 - answer_classifier_acc: 0.2125 - val_loss: 7.0507 - val_time_distributed_5_loss: 1.9799 - val_answer_classifier_loss: 5.0708 - val_time_distributed_5_acc: 0.7294 - val_answer_classifier_acc: 0.2550\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 30s 37ms/step - loss: 6.1014 - time_distributed_5_loss: 1.8623 - answer_classifier_loss: 4.2391 - time_distributed_5_acc: 0.7209 - answer_classifier_acc: 0.2287 - val_loss: 7.1386 - val_time_distributed_5_loss: 1.9474 - val_answer_classifier_loss: 5.1912 - val_time_distributed_5_acc: 0.7294 - val_answer_classifier_acc: 0.2000\n",
      "Epoch 5/10\n",
      "160/800 [=====>........................] - ETA: 24s - loss: 5.9384 - time_distributed_5_loss: 1.7796 - answer_classifier_loss: 4.1588 - time_distributed_5_acc: 0.7228 - answer_classifier_acc: 0.2313"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-70897ddd6739>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0my_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             epochs=epochs)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-8da5e53fd06d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, y_train, x_val, y_val, batch_size, epochs)\u001b[0m\n\u001b[1;32m     74\u001b[0m                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                        \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                        shuffle=True)\n\u001b[0m",
      "\u001b[0;32m~/CMU/Fall-18/Internships/Tensorflow/tfenv/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/CMU/Fall-18/Internships/Tensorflow/tfenv/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CMU/Fall-18/Internships/Tensorflow/tfenv/lib/python3.5/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CMU/Fall-18/Internships/Tensorflow/tfenv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ques = h5.File(\"../../data/data_train_val/data_prepro.h5\", \"r\")\n",
    "ques_train = ques['ques_train'][:n_train]\n",
    "ques_to_image_train = ques['img_pos_train'][:n_train] - 1\n",
    "\n",
    "ans_train = tf.keras.utils.to_categorical(y=ques['answers'][:n_train],\n",
    "                                          num_classes=n_answers)\n",
    "\n",
    "img_feat = h5.File(\"../../data/data_train_val/data_img.h5\", \"r\")\n",
    "img_train = np.array(img_feat['images_train'])[ques_to_image_train]\n",
    "\n",
    "print(img_train.shape)\n",
    "\n",
    "model = VQANet(combine_type='feed_CNN_to_all', \n",
    "               question_embed_dim=question_embed_dim, \n",
    "               lstm_dim=lstm_dim, \n",
    "               n_answers=n_answers)\n",
    "\n",
    "print(model.model.summary())\n",
    "\n",
    "model.train(x_train=[img_train, ques_train], \n",
    "            y_train=[tf.keras.utils.to_categorical(y=ques_train, num_classes=VOCAB_SIZE), ans_train], \n",
    "            x_val=[], \n",
    "            y_val=[], \n",
    "            batch_size=batch_size, \n",
    "            epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
