{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import h5py as h5\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 12602\n",
    "MAX_QUESTION_LEN = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def qa_loss(y_true, y_pred):\n",
    "#     print(y_true[0])\n",
    "#     print(y_pred[0])\n",
    "#     q_true, a_true = y_true[0], y_true[1]\n",
    "#     q_pred, a_pred = y_pred[0][:-1], y_pred[1]\n",
    "    \n",
    "#     q_loss = K.sum(q_true * K.log(q_pred), axis=-1)\n",
    "#     q_loss = K.sum(q_loss, axis=-1)\n",
    "#     a_loss = K.sum(a_true * K.log(a_pred), axis=-1)\n",
    "#     loss = K.sum(y_true * K.log(y_pred), axis=-1)\n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQANet:\n",
    "    def __init__(self, combine_type, question_embed_dim, lstm_dim, n_answers):\n",
    "        self.combine_type = combine_type\n",
    "        self.question_embed_dim = question_embed_dim\n",
    "        self.lstm_dim = lstm_dim\n",
    "        self.n_answers = n_answers\n",
    "        self.build()\n",
    "        \n",
    "    def build(self):\n",
    "        if self.combine_type == 'show-and-tell':\n",
    "            image_features = tf.keras.layers.Input(shape=(4096,), \n",
    "                                                   dtype='float32')\n",
    "            \n",
    "            image_embedding = tf.keras.layers.Dense(units=self.question_embed_dim, \n",
    "                                                    activation='elu',\n",
    "                                                    name='image_embedding')(inputs=image_features)\n",
    "\n",
    "            image_embedding = tf.keras.layers.Reshape((1, self.question_embed_dim))(image_embedding)\n",
    "            \n",
    "            question_input = tf.keras.layers.Input(shape=(MAX_QUESTION_LEN,), \n",
    "                                                   dtype='int32',\n",
    "                                                   name='question_input')\n",
    "            \n",
    "            question_embedding = tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, \n",
    "                                                           output_dim=self.question_embed_dim, \n",
    "                                                           input_length=MAX_QUESTION_LEN,\n",
    "                                                           name='question_embedding')(inputs=question_input)\n",
    "            \n",
    "            image_question_embedding = tf.keras.layers.Concatenate(axis=1, \n",
    "                                                                   name='image_question_embedding')(inputs=[image_embedding, question_embedding])\n",
    "            \n",
    "            question_features, last_h, _ = tf.keras.layers.LSTM(units=self.lstm_dim, \n",
    "                                                                return_sequences=True, \n",
    "                                                                return_state=True, \n",
    "                                                                name='question_generator')(inputs=image_question_embedding)\n",
    "\n",
    "            question_pred = tf.keras.layers.TimeDistributed(layer=tf.keras.layers.Dense(units=VOCAB_SIZE, \n",
    "                                                                  activation='softmax', \n",
    "                                                                  name='word_classifier'))(inputs=question_features)\n",
    "            \n",
    "            # question_pred[:-1] ignores the last output. Need to add <START> and <END>.\n",
    "            question_pred = tf.keras.layers.Lambda(lambda x: x[:, :-1, :], \n",
    "                                                   name='ignore_last_word')(inputs=question_pred)\n",
    "            \n",
    "            answer_features = tf.keras.layers.Dense(units=self.n_answers,\n",
    "                                                activation='elu',\n",
    "                                                name='answer_dense_1')(inputs=last_h)\n",
    "            \n",
    "            answer_pred = tf.keras.layers.Dense(units=self.n_answers,\n",
    "                                                activation='softmax',\n",
    "                                                name='answer_classifier')(inputs=answer_features)\n",
    "            \n",
    "            self.model = tf.keras.Model(inputs=[image_features, question_input], \n",
    "                                        outputs=[question_pred, answer_pred])  \n",
    "            \n",
    "            self.model.compile(loss='categorical_crossentropy', \n",
    "                               optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    def train(self, x_train, y_train, x_val, y_val, batch_size, epochs):\n",
    "        self.model.fit(x=x_train, \n",
    "                       y=y_train, \n",
    "                       batch_size=batch_size, \n",
    "                       epochs=epochs, \n",
    "                       verbose=1,\n",
    "                       validation_split=0.2,\n",
    "                       shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "question_embed_dim = 256\n",
    "lstm_dim = 512\n",
    "n_answers = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 4096)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_embedding (Dense)         (None, 256)          1048832     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "question_input (InputLayer)     (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 256)       0           image_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "question_embedding (Embedding)  (None, 26, 256)      3226112     question_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "image_question_embedding (Conca (None, 27, 256)      0           reshape_3[0][0]                  \n",
      "                                                                 question_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "question_generator (LSTM)       [(None, 27, 512), (N 1574912     image_question_embedding[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 27, 12602)    6464826     question_generator[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "answer_dense_1 (Dense)          (None, 1000)         513000      question_generator[0][1]         \n",
      "__________________________________________________________________________________________________\n",
      "ignore_last_word (Lambda)       (None, 26, 12602)    0           time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "answer_classifier (Dense)       (None, 1000)         1001000     answer_dense_1[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 13,828,682\n",
      "Trainable params: 13,828,682\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 25s 32ms/step - loss: 10.0652 - ignore_last_word_loss: 4.7983 - answer_classifier_loss: 5.2669 - ignore_last_word_acc: 0.7049 - answer_classifier_acc: 0.2188 - val_loss: 6.3759 - val_ignore_last_word_loss: 1.8132 - val_answer_classifier_loss: 4.5627 - val_ignore_last_word_acc: 0.7423 - val_answer_classifier_acc: 0.2550\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 23s 28ms/step - loss: 5.9903 - ignore_last_word_loss: 1.5430 - answer_classifier_loss: 4.4472 - ignore_last_word_acc: 0.7423 - answer_classifier_acc: 0.2238 - val_loss: 6.3997 - val_ignore_last_word_loss: 1.5358 - val_answer_classifier_loss: 4.8640 - val_ignore_last_word_acc: 0.7512 - val_answer_classifier_acc: 0.2550\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 5.6669 - ignore_last_word_loss: 1.3625 - answer_classifier_loss: 4.3044 - ignore_last_word_acc: 0.7500 - answer_classifier_acc: 0.2275 - val_loss: 6.4311 - val_ignore_last_word_loss: 1.4556 - val_answer_classifier_loss: 4.9754 - val_ignore_last_word_acc: 0.7590 - val_answer_classifier_acc: 0.2000\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 5.6176 - ignore_last_word_loss: 1.2939 - answer_classifier_loss: 4.3237 - ignore_last_word_acc: 0.7614 - answer_classifier_acc: 0.2325 - val_loss: 6.5386 - val_ignore_last_word_loss: 1.4119 - val_answer_classifier_loss: 5.1268 - val_ignore_last_word_acc: 0.7760 - val_answer_classifier_acc: 0.2550\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 5.4520 - ignore_last_word_loss: 1.2335 - answer_classifier_loss: 4.2185 - ignore_last_word_acc: 0.7774 - answer_classifier_acc: 0.2263 - val_loss: 6.3568 - val_ignore_last_word_loss: 1.3579 - val_answer_classifier_loss: 4.9990 - val_ignore_last_word_acc: 0.7842 - val_answer_classifier_acc: 0.2550\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 5.3777 - ignore_last_word_loss: 1.1811 - answer_classifier_loss: 4.1966 - ignore_last_word_acc: 0.7851 - answer_classifier_acc: 0.2425 - val_loss: 6.2977 - val_ignore_last_word_loss: 1.3283 - val_answer_classifier_loss: 4.9694 - val_ignore_last_word_acc: 0.7917 - val_answer_classifier_acc: 0.2550\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 23s 28ms/step - loss: 5.3193 - ignore_last_word_loss: 1.1455 - answer_classifier_loss: 4.1739 - ignore_last_word_acc: 0.7946 - answer_classifier_acc: 0.2238 - val_loss: 6.3674 - val_ignore_last_word_loss: 1.3092 - val_answer_classifier_loss: 5.0583 - val_ignore_last_word_acc: 0.8019 - val_answer_classifier_acc: 0.2000\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 5.2922 - ignore_last_word_loss: 1.1203 - answer_classifier_loss: 4.1719 - ignore_last_word_acc: 0.8035 - answer_classifier_acc: 0.2238 - val_loss: 6.4000 - val_ignore_last_word_loss: 1.2960 - val_answer_classifier_loss: 5.1039 - val_ignore_last_word_acc: 0.8052 - val_answer_classifier_acc: 0.2550\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 23s 28ms/step - loss: 5.2704 - ignore_last_word_loss: 1.0931 - answer_classifier_loss: 4.1773 - ignore_last_word_acc: 0.8080 - answer_classifier_acc: 0.2238 - val_loss: 6.5828 - val_ignore_last_word_loss: 1.2775 - val_answer_classifier_loss: 5.3053 - val_ignore_last_word_acc: 0.8123 - val_answer_classifier_acc: 0.2550\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 23s 28ms/step - loss: 5.2804 - ignore_last_word_loss: 1.0644 - answer_classifier_loss: 4.2160 - ignore_last_word_acc: 0.8110 - answer_classifier_acc: 0.2337 - val_loss: 6.3180 - val_ignore_last_word_loss: 1.2602 - val_answer_classifier_loss: 5.0578 - val_ignore_last_word_acc: 0.8146 - val_answer_classifier_acc: 0.2550\n"
     ]
    }
   ],
   "source": [
    "img_feat = h5.File(\"../../data/data_train_val/data_img.h5\", \"r\")\n",
    "img_train = img_feat['images_train'][:1000]\n",
    "\n",
    "ques = h5.File(\"../../data/data_train_val/data_prepro.h5\", \"r\")\n",
    "ques_train = ques['ques_train'][:1000]\n",
    "\n",
    "ans_train = tf.keras.utils.to_categorical(y=ques['answers'][:1000],\n",
    "                                          num_classes=n_answers)\n",
    "\n",
    "model = VQANet(combine_type='show-and-tell', \n",
    "               question_embed_dim=question_embed_dim, \n",
    "               lstm_dim=lstm_dim, \n",
    "               n_answers=n_answers)\n",
    "\n",
    "print(model.model.summary())\n",
    "\n",
    "# Issue: ques_train input and output are the same.\n",
    "model.train(x_train=[img_train, ques_train], \n",
    "            y_train=[tf.keras.utils.to_categorical(y=ques_train, num_classes=VOCAB_SIZE), ans_train], \n",
    "            x_val=[], \n",
    "            y_val=[], \n",
    "            batch_size=batch_size, \n",
    "            epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
